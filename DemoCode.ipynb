{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cefa64-dc00-4f61-bad7-076f6a323c48",
   "metadata": {},
   "source": [
    "# Simple Segmentation ReFree metric example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca25aa3-4e03-4dd1-84f3-0aed2bc10905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import segeval\n",
    "import numpy as np\n",
    "\n",
    "#Define embedding model\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1220bdeb-c941-49f4-b20a-34d82863ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define necessary functions\n",
    "\n",
    "#L2 distance\n",
    "def l2dist(point1,listofpoints2):\n",
    "    if len(listofpoints2.shape) > 1:\n",
    "    \n",
    "        dists = np.zeros((len(listofpoints2),))\n",
    "        for idx,point2 in enumerate(listofpoints2):\n",
    "            dists[idx] = np.sqrt(np.sum(np.square(point2-point1)))\n",
    "    else:\n",
    "        dists = np.sqrt(np.sum(np.square(listofpoints2-point1)))\n",
    "    return dists\n",
    "\n",
    "#Segmentation metric code\n",
    "def segmentation_re_free(X, labels, dist = l2dist):\n",
    "\n",
    "    dist_method = dist\n",
    "    n_labels = len(np.unique(labels))\n",
    "    intra_dists = np.zeros((n_labels,)) \n",
    "    centroids = np.zeros((n_labels, len(X[0])), dtype=float)\n",
    "    length1segments = 0\n",
    "    for k in range(n_labels):\n",
    "        cluster_k = X[np.where(labels == k),:][0]\n",
    "        centroid = cluster_k.mean(axis=0)\n",
    "        centroids[k] = centroid\n",
    "        if len(cluster_k) > 1:\n",
    "            correction_factor = 1 -1/np.sqrt(len(cluster_k))\n",
    "        else:\n",
    "            correction_factor =  0.25 #ends up not mattering, but prevents nan\n",
    "            print('Warning, segment of length 1 detected')\n",
    "            length1segments += 1\n",
    "                \n",
    "        intra_dists[k] = np.average(dist_method(centroid, cluster_k))/correction_factor\n",
    "\n",
    "    if length1segments > 0:\n",
    "        print('There are ' + str(length1segments) + ' segments of length 1 found in this segmentation. This may create an artificially low score.')\n",
    "    centroid_distances = np.zeros((n_labels,3))\n",
    "    centroid_distances[0,2] = dist_method(centroids[0],centroids[1])\n",
    "    centroid_distances[-1,0] = dist_method(centroids[-1],centroids[-2])\n",
    "\n",
    "    for k in np.arange(1,n_labels-1):\n",
    "        centroid_distances[k,:] = dist_method(centroids[k],centroids[k-1:k+2])\n",
    "\n",
    "    centroid_distances = np.delete(centroid_distances,1,1)\n",
    "\n",
    "    if np.allclose(intra_dists, 0) or np.allclose(centroid_distances, 0):\n",
    "        return 0.0\n",
    "\n",
    "    centroid_distances[centroid_distances == 0] = np.inf\n",
    "\n",
    "\n",
    "    combined_intra_dists = np.zeros((n_labels,2)) \n",
    "    combined_intra_dists[0,1] = intra_dists[0]+intra_dists[1]\n",
    "    combined_intra_dists[-1,0] = intra_dists[-1] + intra_dists[-2]\n",
    "    for k in np.arange(1,n_labels-1):\n",
    "        \n",
    "        combined_intra_dists[k,0] = intra_dists[k] + intra_dists[k-1]\n",
    "        combined_intra_dists[k,1] = intra_dists[k] + intra_dists[k+1]\n",
    "\n",
    "\n",
    "    scores = np.max(combined_intra_dists / centroid_distances, axis=1)\n",
    "    return np.mean(scores)\n",
    "\n",
    "#Helper function for segeval code\n",
    "def formatSegments(segs):\n",
    "    x_arrstr = np.char.mod('%i', segs)\n",
    "    formattedSegs = \"\".join(x_arrstr)\n",
    "    return formattedSegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74249729-d6ea-44c9-bdea-e382e19a4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create some made up text about a segmentation example\n",
    "sampleText = '''\n",
    "This block of text is segmented into sets of sentences that relate to one another. \n",
    "The relationship of adjacent sentences in this segmentation is based on semantic meaning. \n",
    "\n",
    "The way that we have chosen to mark these segmentations is both through highlighting and font changes. \n",
    "An alternate (poor) segmentation is marked with hash marks. The reason we have chosen both font and \n",
    "color changes is to make this more easily readable for those that are colorblind. The highlighting \n",
    "colors have also been chosen with different luminosity in order to aid differentiation by those that \n",
    "are colorblind.\n",
    "\n",
    "This work focuses on segmentation at the sentence boundary, although some segmentation work \n",
    "happens at the sub-sentence level. Segmentation at the level done in this work is often used as a \n",
    "way to split apart large texts into relevant parts as a pre-processing step before other operations \n",
    "such as summarization. This can be necessary because some algorithms are not able to handle rather \n",
    "long inputs, or it can improve quality of results by grouping similar content.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26135331-8659-4862-ae90-16d6ecabda62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create sentence embeddings\n",
    "sentences = sampleText.split('.')\n",
    "embeddings = embedding_model.encode(sentences[:-1])#ignore last part of split list\n",
    "\n",
    "#Define made up boundary sets, with 0 being topically good and 1 being shifted.\n",
    "boundarySet0 = np.asarray([0,0,1,0,0,0,1,0,0])\n",
    "boundarySet1 = np.asarray([0,0,0,1,0,0,0,1,0])\n",
    "\n",
    "#Create labels for clustering\n",
    "segmentationLabels0 = np.cumsum(boundarySet0)\n",
    "segmentationLabels1 = np.cumsum(boundarySet1)\n",
    "\n",
    "#Convert boundary format from boundary set to mass format\n",
    "reference_topic_segments = segeval.convert_nltk_to_masses(formatSegments(boundarySet0))\n",
    "candidate_topic_segments = segeval.convert_nltk_to_masses(formatSegments(boundarySet1))\n",
    "\n",
    "#Generate classic metrics\n",
    "seg_pk = segeval.pk(reference_topic_segments, candidate_topic_segments)\n",
    "seg_wd = segeval.window_diff(reference_topic_segments, candidate_topic_segments)\n",
    "seg_s = segeval.segmentation_similarity(reference_topic_segments, candidate_topic_segments)\n",
    "seg_b = segeval.boundary_similarity(reference_topic_segments, candidate_topic_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f056d95-5969-44c7-acd3-e234e4a9c705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Segmentation ReFree score for the first segmenation of the text is 3.0498791797046145\n",
      "The Segmentation ReFree score for the second segmenation of the text is 4.561183315917675\n",
      "For reference, the P_k score is 0.5, the WindowDiff score is 0.5, the Segmentation Similarity is 0.8888888888888888888888888889, and the Boundary Similarity is 0.5\n"
     ]
    }
   ],
   "source": [
    "print('The Segmentation ReFree score for the first segmenation of the text is ' + str(segmentation_re_free(embeddings, segmentationLabels0)))\n",
    "print('The Segmentation ReFree score for the second segmenation of the text is ' + str(segmentation_re_free(embeddings, segmentationLabels1)))\n",
    "print('For reference, the P_k score is ' + str(seg_pk) + ', the WindowDiff score is ' + str(seg_wd) + ', the Segmentation Similarity is ' + str(seg_s) + ', and the Boundary Similarity is '+ str(seg_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44e686-4338-4001-92b5-b28da83676f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
